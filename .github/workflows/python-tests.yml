name: Python Tests

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:  # Allow manual triggering

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.11', '3.12']

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov requests-mock
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    # Create necessary directories
    - name: Create data directories
      run: |
        mkdir -p data/documents/vector_store
        mkdir -p data/summaries
        touch data/documents/.gitkeep
        touch data/summaries/.gitkeep
        echo "Test document" > data/documents/test_document.txt
        echo "Data directories created for tests"
    
    # Start a mock server for Ollama
    - name: Set up mock Ollama service
      run: |
        # Create a simple mock server using Python Flask
        echo "Creating mock Ollama server..."
        cat > mock_ollama_server.py << 'EOF'
        from flask import Flask, request, jsonify
        import json

        app = Flask(__name__)

        @app.route('/api/chat', methods=['POST'])
        def chat():
            response_data = {
                "model": "test-model",
                "created_at": "2023-08-04T08:52:19.385406455Z",
                "message": {
                    "role": "assistant",
                    "content": json.dumps({"steps": []}) if request.json.get('format') == 'json' else "This is a mock response",
                },
                "done": True
            }
            return jsonify(response_data)

        @app.route('/api/embeddings', methods=['POST'])
        def embeddings():
            response_data = {
                "model": "test-embed-model",
                "embedding": [0.1] * 768
            }
            return jsonify(response_data)

        if __name__ == '__main__':
            app.run(host='0.0.0.0', port=11434)
        EOF

        # Install Flask and start the mock server in the background
        pip install flask
        python mock_ollama_server.py > mock_ollama.log 2>&1 &
        echo "Mock Ollama server started on port 11434"
        sleep 2 # Give the server a moment to start
        
        # Verify the server is running
        curl -s http://localhost:11434/api/chat -d '{"model":"test-model","messages":[{"role":"user","content":"test"}]}' || echo "Mock server not responding"
    
    - name: Run tests
      run: |
        # Set up environment for tests
        export OLLAMA_BASE_URL=http://localhost:11434
        export OLLAMA_MODEL=test-model
        export OLLAMA_EMBED_MODEL=test-embed-model

        # Run only non-interactive tests
        pytest --cov=agent --ignore=tests/test_cli_summary.py tests/
      env:
        PYTHONPATH: ${{ github.workspace }}
        # Use localhost for the mock server
        OLLAMA_BASE_URL: http://localhost:11434
        OLLAMA_MODEL: test-model
        OLLAMA_EMBED_MODEL: test-embed-model 